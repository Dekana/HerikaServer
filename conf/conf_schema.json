{
  "PLAYER_NAME": {"userlvl":"basic","type":"string","description":"Your current character name.","_title":"Main Configuration"},
  "DBDRIVER": {"userlvl":"wip","type":"select","values":["postgresql"],"description":"Do not change."},
  "HERIKA_NAME": {"userlvl":"basic","type":"string","description":"NPC Name. MUST MATCH their Skyrim in-game NPC name!<br>If you are in the default profile <b>YOU MUST</b> leave it as <i>The Narrator</i>!<br><b>You can change profiles by clicking the blue button in the top left.</b>"},
  "PROMPT_HEAD": {"userlvl":"pro","type":"longstring","description":"System Prompt. Defines the rules of the roleplay."},
  "PLAYER_BIOS": {"userlvl":"pro","type":"longstring","description":"Player character description. Any info here will be known by all AI NPC's."},
  "HERIKA_PERS": {"userlvl":"basic","type":"longstring","description":"NPC Personality. Treat it like a DnD character bio.<br><b>Variables you can use:</b><br>#PLAYER_NAME# = Your player name","helpurl":"https://www.nexusmods.com/skyrimspecialedition/articles/5321"},
  "dynamic_profile_b1": {"userlvl":"pro","type":"util","description":"Use LLM (the regular connector not the JSON!) to update an NPC's personality dynamically, based on recent events.<br><strong>Requires max_tokens set to a value at 500 or higher.</strong>","action":"action_dynamic_profile_b1.php","name":"Advanced Auto Fill"},
  "dynamic_profile_b2": {"userlvl":"pro","type":"util","description":"Use LLM (the regular connector not the JSON!) to update an NPC's personality dynamically, based on recent events. This is a shorter version for less important NPCs.<br><strong>Requires max_tokens to a value of 300 or higher.</strong>","action":"action_dynamic_profile_b1.php?short=yes","name":"Simple Auto Fill"},
  "DYNAMIC_PROFILE":{"userlvl":"pro","type":"boolean","description":"Will trigger dynamic profile updates during certain ingame events (such as sleeping). Will cause the AI personality to dynamically change during gameplay based on player interaction."},
  "MINIME_T5":{"userlvl":"basic","type":"boolean","scope":"global","description":"Enable MiniMeT5 LLM. Helps dumber LLM's be more accurate with action and memory functions. Must be enabled in DwemerDistro under Tools/components. <br> <strong> Must be configued in default profile and only works in English!</strong>"},
  "RECHAT_H": {"userlvl":"basic","type":"integer","description":"Rechat Rounds. Higher values will increase the amount of rounds NPC's will talk amongst themselves.<br>1 = 1 Round | 2 = 2 Rounds | 3 = 3 Rounds etc","_title":"Advanced Configuration"},
  "RECHAT_P": {"userlvl":"basic","type":"integer","description":"Rechat Probability.<br>0 = Always | 50 = Sometimes | 100 = Never"},
  "BORED_EVENT": {"userlvl":"pro","type":"integer","description":"Bored Event Probability. Chance of an NPC starting a random conversation after a set period of time.<br>0 = NEVER | 1 = 50% | 3 = 75% | 9 = 90% | 99 = 99% "},
  "CONTEXT_HISTORY": {"userlvl":"basic","type":"integer","description":"Amount of context history (dialogue and events) that will be sent to LLM. Improves short term memory.<br>Higher Context = more tokens used and slower response time."},
  "HTTP_TIMEOUT": {"userlvl":"pro","type":"integer","description":"Timeout for AI requests. "},
  "CORE_LANG": {"userlvl":"pro","type":"select","description":"Custom Language. The lang folder is in the CHIM Server. Leave it blank for English."},
  "NEWQUEUE": {"userlvl":"wip","scope":"constant","type":"boolean","description":"Leave as is. Can not be changed!"},
  "MAX_WORDS_LIMIT": {"userlvl":"basic","type":"integer","description":"Enforce a word limit for AI's responses. Leave as 0 to have no limit."},
  "BOOK_EVENT_FULL": {"userlvl":"pro","type":"boolean","description":"Send full contents of book instead of only the book title to the AI. This will consume more tokens, but the AI will accurately summarize any book or note!"},
  "BOOK_EVENT_ALWAYS_NARRATOR": {"userlvl":"basic","type":"boolean","description":"The Narrator will be the only one to summarize books.<br><strong>SET THIS ON default profile to apply to all NPCs.</strong>","scope":"global"},
  "NARRATOR_TALKS": {"userlvl":"basic","type":"boolean","description":"Enable the Narrator.","scope":"global"},
  "NARRATOR_WELCOME": {"userlvl":"basic","type":"boolean","description":"The Narrator will give you a quick recap of what happened previously after you have loaded a save game.","scope":"global"},
  "LANG_LLM_XTTS": {"userlvl":"wip","type":"boolean","description":"XTTS Only! Will offer a language field to LLM, and will try match to XTTSv2 language."},
  "HERIKA_ANIMATIONS": {"userlvl":"pro","type":"boolean","description":"Will issue animations for the NPC to play"},
  "EMOTEMOODS": {"userlvl":"pro","type":"longstring","description":"List of moods passed to LLM (comma separated). Some of them will trigger appropriate animations if animations are enabled"},
  "SUMMARY_PROMPT": {"userlvl":"wip","type":"longstring","description":"Instructions added when generating summaries for memories and other features.","scope":"global"},
  "CONNECTORS": {"type":"selectmultiple","values":["openaijson","koboldcppjson","openrouterjson","openai","koboldcpp","openrouter"],"description":"AI Service(s) to be used for most AI features.<br>Select the service(s) you have configured for AI/LLM Connectors below.<br><strong>Non JSON connectors are legacy and no longer supported. We can not debug or fix any issues you have with them!</strong><br><br><br><br>Make sure to click the <strong>Current AI Service</strong> button at the top of the page if you change connectors!","_title":"AI/LLM Service Selection"},
  "CONNECTORS_DIARY": {"type":"select","values":["openrouter","openai","koboldcpp"],"description":"<strong>Used for creating diary entries and memories!<br><br>You will need to place your API key in the regular/non-JSON connector for this to work!</strong>"},
  "CONNECTOR": {
    "_title":"AI/LLM Connectors",
    "openrouterjson": {
      "_title":"OpenRouter API (JSON)",
      "url": {"type":"url","description":"OpenRouter API endpoint"},
      "model": {"type":"ormodellist","description":"<strong>Must be JSON/Instruct type of Model!</strong><br>FREE MODELS ARE NOT RECOMMENDED!<br>If you change model use buttons below to set new parameters!","helpurl":"https://openrouter.ai/docs#models"},
      "PROVIDER": {"type":"string","description":"Leave as blank unless you want to manually select a provider from OpenRouter.","helpurl":"https://openrouter.ai/docs/provider-routing"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate."},
      "temperature": {"type":"number","description":"LLM parameter temperature","helpurl":"https://openrouter.ai/docs#format"},
      "presence_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter presence_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "frequency_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter frequency_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "repetition_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter repetition_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p","helpurl":"https://openrouter.ai/docs#format"},
      "top_k": {"userlvl":"pro","type":"number","description":"LLM parameter top_k","helpurl":"https://openrouter.ai/docs#format"},
      "min_p": {"userlvl":"pro","type":"number","description":"LLM parameter min_p","helpurl":"https://openrouter.ai/docs#format"},
      "top_a": {"userlvl":"pro","type":"number","description":"LLM parameter top_a","helpurl":"https://openrouter.ai/docs#format"},
      "ENFORCE_JSON": {"type":"boolean","description":"Will attempt to enforce dumb LLM's to stay in JSON format. Leave as default, only works with specific models.","helpurl":"https://openrouter.ai/docs#format"},
      "PREFILL_JSON": {"type":"boolean","description":"Will attempt to prefill the JSON AI response for some dumber LLM's. Leave as default, only works with specific models.","helpurl":"https://openrouter.ai/docs#format"},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."},
      "get_parms1": {"type":"util","description":"Autofill parameter settings for the currently selected model for minimal randomness in AI response (P10)","action":"action_openrouterjson_get_parm_p1.php?P=10","name":"Autofill Parameters: Low Randomness","helpurl":"https://openrouter.ai/docs/parameters"},
      "get_parms5": {"type":"util","description":"Autofill parameter settings for the currently selected model for some randomness in AI response (P50)","action":"action_openrouterjson_get_parm_p1.php?P=50","name":"Autofill Parameters: Medium Randomness","helpurl":"https://openrouter.ai/docs/parameters"},
      "get_parms9": {"type":"util","description":"Autofill parameter settings for the currently selected model for very randomness in AI response (P90)","action":"action_openrouterjson_get_parm_p1.php?P=90","name":"Autofill Parameters: High Randomness","helpurl":"https://openrouter.ai/docs/parameters"},
      "API_KEY":  {"type":"apikey","description":"OpenRouter key","code":"OPENAI_API_KEY"},
      "xreferer": {"userlvl":"pro","type":"string","description":"Stub needed header. Keep default."},
      "xtitle": {"userlvl":"pro","type":"string","description":"Stub needed header. Keep default."},
      "json_schema": {"type":"boolean","description":"Enable OpenRouter Json schema. Does not work with all models. You must set a provider that supports structured outputs.","helpurl":"https://openrouter.ai/docs/structured-outputs#model-support"}
    },
    "openrouter": {
      "_title":"OpenRouter API",
      "url": {"type":"url","description":"OpenRouter API endpoint"},
      "model": {"type":"ormodellist","description":"Model to use.<br>FREE MODELS ARE NOT RECOMMENDED!<br>If you change model use buttons below to set new parameters!","helpurl":"https://openrouter.ai/docs#models"},
      "PROVIDER": {"type":"string","description":"Leave as blank unless you want to manually select a provider from OpenRouter.","helpurl":"https://openrouter.ai/docs/provider-routing"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate."},
      "temperature": {"type":"number","description":"LLM parameter temperature","helpurl":"https://openrouter.ai/docs#format"},
      "presence_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter presence_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "frequency_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter frequency_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "repetition_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter repetition_penalty","helpurl":"https://openrouter.ai/docs#format"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p","helpurl":"https://openrouter.ai/docs#format"},
      "top_k": {"userlvl":"pro","type":"number","description":"LLM parameter top_k","helpurl":"https://openrouter.ai/docs#format"},
      "min_p": {"userlvl":"pro","type":"number","description":"LLM parameter min_p","helpurl":"https://openrouter.ai/docs#format"},
      "top_a": {"userlvl":"pro","type":"number","description":"LLM parameter top_a","helpurl":"https://openrouter.ai/docs#format"},
      "API_KEY":  {"type":"apikey","description":"OpenRouter key","code":"OPENAI_API_KEY"},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."},
      "xreferer": {"userlvl":"pro","type":"string","description":"Stub needed header. Keep default."},
      "xtitle": {"userlvl":"pro","type":"string","description":"Stub needed header. Keep default."},
      "get_parms1": {"type":"util","description":"Autofill parameter settings for the currently selected model for minimal randomness in AI response (P10)","action":"action_openrouter_get_parm_p1.php?P=10","name":"Autofill Parameters: Low Randomness","helpurl":"https://openrouter.ai/docs/parameters"},
      "get_parms5": {"type":"util","description":"Autofill parameter settings for the currently selected model for some randomness in AI response (P50)","action":"action_openrouter_get_parm_p1.php?P=50","name":"Autofill Parameters: Medium Randomness","helpurl":"https://openrouter.ai/docs/parameters"},
      "get_parms9": {"type":"util","description":"Autofill parameter settings for the currently selected model for very randomness in AI response (P90)","action":"action_openrouter_get_parm_p1.php?P=90","name":"Autofill Parameters: High Randomness","helpurl":"https://openrouter.ai/docs/parameters"}
    },
    "openaijson": {
      "_title":"OpenAI/ChatGPT API (JSON)",
      "url": {"type":"url","description":"OpenAI API endpoint"},
      "model": {"type":"string","description":"Model to use","helpurl":"https://platform.openai.com/docs/models/"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate"},
      "temperature": {"type":"number","description":"LLM parameter temperature","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "presence_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter presence_penalty","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "frequency_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter frequency_penalty","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "API_KEY":  {"type":"apikey","description":"OpenAI API key","code":"OPENAI_API_KEY","helpurl":"https://platform.openai.com/account/api-keys"},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."},
      "json_schema": {"type":"boolean","description":"Enable OpenAI Json schema. Does not work witl all OpenAI's models","helpurl":"https://platform.openai.com/docs/guides/structured-outputs?lang=js"}
    },
    "openai": {
      "_title":"OpenAI/ChatGPT API",
      "url": {"type":"url","description":"OpenAI API endpoint"},
      "model": {"type":"string","description":"Model to use","helpurl":"https://platform.openai.com/docs/models/"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate"},
      "temperature": {"type":"number","description":"LLM parameter temperature","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "presence_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter presence_penalty","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "frequency_penalty": {"userlvl":"pro","type":"number","description":"LLM parameter frequency_penalty","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p","helpurl":"https://platform.openai.com/docs/api-reference/completions/create"},
      "API_KEY":  {"type":"apikey","description":"OpenAI API key","code":"OPENAI_API_KEY","helpurl":"https://platform.openai.com/account/api-keys"},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."}
    },
    "koboldcppjson": {
      "_title":"KoboldCPP API (JSON)",
      "url": {"type":"url","description":"Kobold ideally should be running on the same machine as DwemerDistro!<br>Must use your computers, not the DwemerDistro, IP Address.<br>Can be found by running the command 'ipconfig' in your CMD prompt.<br>Example: http://your-local-ip:8008","helpurl":"https://www.nexusmods.com/skyrimspecialedition/articles/5742"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate"},
      "temperature": {"type":"number","description":"LLM parameter temperature"},
      "rep_pen": {"type":"number","description":"LLM parameter rep_pen"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p"},
      "min_p": {"userlvl":"pro","type":"number","description":"LLM parameter min_p"},
      "top_k": {"userlvl":"pro","type":"number","description":"LLM parameter top_k"},
      "PREFILL_JSON": {"type":"boolean","description":"Will prefill JSON, which is useful for some AI models, and destroy others."},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."},
      "newline_as_stopseq": {"type":"boolean","description":"A new line in the output that will be considered a stop sequence. Recommended to leave as default."},
      "use_default_badwordsids": {"type":"boolean","description":"Unban End of Sentence (EOS) tokens. If set to false the LLM will stop generating when it detects an EOS token."},
      "eos_token": {"type":"string","description":"EOS token LLM uses. Only works if use_default_badwordsids is enabled."},
      "template": {"type":"select","values":["vicuna-1","vicuna-1.1","alpaca","synthia","extended-alpaca","superHOT","chatml","chatml-c","zephyr","openchat","dreamgen","neuralchat","phi","llama3","gromenauer","gemma2","alpacajson","mistral-ins"],"description":"Prompt Format. Specified in the HuggingFace model card"},
      "grammar": {"type":"boolean","description":"Enforces use of JSON grammar. True to enforce (generation speed loss, but json format guaranteed). if false, the generation speed will be better but will depend on the model to produce valid JSON output." }
    },
    "koboldcpp": {
      "_title":"KoboldCPP API",
      "url": {"type":"url","description":"Kobold ideally should be running on the same machine as DwemerDistro!<br>Must use your computers, not the DwemerDistro, IP Address.<br>Can be found by running the command 'ipconfig' in your CMD prompt.<br>Example: http://your-local-ip:8008","helpurl":"https://www.nexusmods.com/skyrimspecialedition/articles/5742"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate"},
      "temperature": {"type":"number","description":"LLM parameter temperature"},
      "rep_pen": {"userlvl":"pro","type":"number","description":"LLM parameter rep_pen"},
      "top_p": {"userlvl":"pro","type":"number","description":"LLM parameter top_p"},
      "min_p": {"userlvl":"pro","type":"number","description":"LLM parameter min_p"},
      "top_k": {"userlvl":"pro","type":"number","description":"LLM parameter top_k"},
      "MAX_TOKENS_MEMORY": {"type":"integer","description":"Maximum tokens to generate when summarizing, such as writing to diary."},
      "newline_as_stopseq": {"type":"boolean","description":"A new line in the output that will be considered a stop sequence. Recommended to leave as default."},
      "use_default_badwordsids": {"type":"boolean","description":"Unban End of Sentence (EOS) tokens. If set to false the LLM will stop generating when it detects an EOS token."},
      "eos_token": {"type":"string","description":"EOS token LLM uses. Only works if use_default_badwordsids is enabled."},
      "template": {"type":"select","values":["vicuna-1","vicuna-1.1","alpaca","synthia","extended-alpaca","superHOT","chatml","chatml-c","zephyr","openchat","dreamgen","neuralchat","phi","llama3","gromenauer","gemma2","mistral-ins"],"description":"Prompt Format. Specified in the HuggingFace model card"}
    }
  },
  "TTSFUNCTION": {"type":"select","values":["none","melotts","xtts-fastapi","mimic3","xvasynth","azure","11labs","gcp","openai","convai"],"description":"Text-to-Speech service options. Used to generate AI NPC voice.","_title":"Text-to-Speech Service"},
  "TTS": {
    "_title":"Text-to-Speech Service",
    "MELOTTS": {
      "_title":"MeloTTS (Installed in DwemerDistro)",
      "endpoint":{"type":"url","description":"Endpoint URL. Should be 'http://127.0.0.1:8084' if using default installation","helpurl":"https://github.com/myshell-ai/MeloTTS"},
      "language":{"type":"select","values":["EN","ES","FR","ZH","JP","KR"],"description":"Language Model. Should be EN if using default installation"},
      "speed":{"type":"number","description":"Speech Speed"},
      "voiceid":{"type":"string","description":"Voice ID. Should be set automatically for most Vanilla Skyrim NPCs. Uses Skyrim VoiceType ID, e.g. femaleeventoned.<b> Click the help/doc link for full list of voiceids!</b>", "helpurl":"https://docs.google.com/document/d/12KBar_VTn0xuf2pYw9MYQd7CKktx4JNr_2hiv4kOx3Q/edit?tab=t.0#heading=h.21ics3hex54a"}
    },
    "XTTSFASTAPI": {
      "_title":"CHIM XTTS (Installed in DwemerDistro)",
      "endpoint":{"type":"url","description":"End point URL. Leave as default if you installed XTTS through the Distro.<br>Be warned it takes 4GB of VRAM to run it!<br>You can run it on the cloud, click the help/doc link for instructions.", "helpurl":"https://www.nexusmods.com/skyrimspecialedition/articles/7673"},
      "language":{"type":"select","values":[  "ar","pt","zh-cn", "cs","nl","en","fr", "de", "it", "pl", "ru", "es", "tr","ja", "ko","hu","hi"],"description":"Language"},
      "voiceid":{"type":"string","description":"Generated voice file name. Click link to go to XTTS management to view voiceids.<br><b>To use Mantella XTTS voices you must install the MinAI plugin!</b>","helpurl":"/HerikaServer/ui/xtts_clone.php"}
    },
    "MIMIC3": {
      "_title":"MIMIC3 (Installed in DwemerDistro)",
      "URL": {"type":"url","description":"MIMIC3 Service URL."},
      "voice": {"type":"string","description":"Voice code"},
      "rate": {"type":"number","description":"Talk speed"},
      "volume": {"type":"integer","description":"Volume"}
    },
    "XVASYNTH": {
      "_title":"xVASynth",
      "url":{"type":"url","description":"xVASynth ideally should be running on the same machine as DwemerDistro!<br>Must use your computers, not the DwemerDistro, IP Address.<br>Can be found by running the command 'ipconfig' in your CMD prompt.<br>Example: http://your-local-ip:8008<br>Click the <b>help/doc</b> link for more info.","helpurl":"https://docs.google.com/document/d/12KBar_VTn0xuf2pYw9MYQd7CKktx4JNr_2hiv4kOx3Q/edit?tab=t.0#heading=h.3tf6myep6rmw"},
      "base_lang":{"type":"string","description":"Base language"},
      "modelType":{"type":"string","description":"modelType"},
      "model":{"type":"string","description":"Model"},
      "pace":{"type":"number","description":"Pace"},
      "waveglowPath":{"type":"string","description":"waveglowPath (relative)"},
      "vocoder":{"type":"string","description":"vocoder"},
      "distroname":{"type":"string","description":"Leave as default!"}
    },
    "AZURE": {
      "_title":"Azure Text-To-Speech",
      "fixedMood": {"type":"string","description":"Force mood (voice style)","helpurl":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#use-speaking-styles-and-roles"},
      "region": {"type":"string","description":"Region location of your API key"},
      "voice": {"type":"string","description":"Voice","helpurl":"https://speech.microsoft.com/portal/voicegallery"},
      "volume": {"type":"integer","description":"Volume","helpurl":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#adjust-prosody"},
      "rate": {"userlvl":"pro","type":"number","description":"Talk speed","helpurl":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#adjust-prosody"},
      "countour": {"userlvl":"pro","type":"string","description":"Voice contour","helpurl":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice#adjust-prosody"},
      "validMoods": {"userlvl":"pro","type":"selectmultiple","values":["angry","chat","cheerful","customerservice","empathetic","excited","friendly","hopeful","narration-professional","newscast-casual","newscast-formal","sad","shouting","terrified","unfriendly","whispering","default","dazed"],"description":"Allowed voice styles"},
      "API_KEY": {"type":"apikey","description":"Azure TTS API KEY","code":"AZURE_API_KEY"}
    },
    "openai": {
      "_title":"OpenAI TTS",
      "endpoint":{"type":"url","description":"Endpoint URL","helpurl":"https://platform.openai.com/docs/guides/text-to-speech"},
      "API_KEY":{"type":"apikey","description":"API KEY"},
      "voice":{"type":"select","values":["alloy", "echo", "fable", "onyx", "nova", "shimmer"],"description":"Voice ID","helpurl":"https://platform.openai.com/docs/guides/text-to-speech"},
      "model_id":{"type":"select","values":["tts-1", "tts-1-hd"],"description":"Model","helpurl":"https://platform.openai.com/docs/guides/text-to-speech"}
    },
    "ELEVEN_LABS": {
      "_title":"ElevenLabs Text-To-Speech",
      "voice_id": {"type":"string","description":"Voice code","helpurl":"https://www.nexusmods.com/skyrimspecialedition/articles/5578"},
      "optimize_streaming_latency": {"type":"string","description":"Optimize Streaming Latency","helpurl":"https://docs.elevenlabs.io/api-reference/text-to-speech"},
      "model_id": {"type":"string","description":"Model ID","helpurl":"https://beta.elevenlabs.io/speech-synthesis"},
      "stability":{"userlvl":"pro","type":"number","description":"Stability"},
      "similarity_boost": {"userlvl":"pro","type":"number","description":"Similarity_Boost"},
      "style": {"type":"number","description":"Style"},
      "API_KEY": {"type":"apikey","description":"Eleven Labs API key.","code":"11LABS_API_KEY"}
    },
    "GCP": {
      "_title":"Google Cloud Platform Text-To-Speech",
      "GCP_SA_FILEPATH": {"type":"string","description":"Google Cloud Platform auth file. Should be placed in the data folder.","helpurl":"https://www.nexusmods.com/skyrimspecialedition/articles/5581"},
      "voice_name":{"type":"string","description":"Voice","helpurl":"https://cloud.google.com/text-to-speech/docs/voices"},
      "voice_languageCode":{"type":"string","description":"Language code","helpurl":"https://developers.google.com/admin-sdk/directory/v1/languages"},
      "ssml_rate":{"type":"number","description":"Rate"},
      "ssml_pitch":{"type":"string","description":"Pitch"}
    },
    "CONVAI": {
      "_title":"CONVAI TTS",
      "endpoint":{"type":"url","description":"End point URL","helpurl":"https://docs.convai.com/api-docs/reference/core-api-reference/standalone-voice-api/text-to-speech-api"},
      "API_KEY":{"type":"apikey","description":"API KEY"},
      "language":{"type":"select","values":["ar", "cmn-CN", "de-DE", "en-US", "es-ES", "es-MX", "es-US", "fr-FR", "hi-IN", "it-IT", "js-JP", "kk-KZ", "ko-KR", "nl-BE", "nl-NL", "pl-PL", "pt-BR", "pt-PT", "ru-RU", "sv-SE", "tr-TR", "vi-VN", "yue-HK", "zh-HK"],"description":"Language","helpurl":"https://platform.openai.com/docs/guides/text-to-speech"},
      "voiceid":{"type":"string","description":"Voice id (check compatability with language)","helpurl":"https://docs.convai.com/api-docs/reference/core-api-reference/standalone-voice-api/text-to-speech-api"},
      "description":"VoiceId","helpurl":"https://docs.convai.com/api-docs/reference/core-api-reference/standalone-voice-api/text-to-speech-api"
      }
  },
  "TTSFUNCTION_PLAYER": {"type":"select","userlvl":"basic","scope":"global","values":["none","melotts","xtts-fastapi","xvasynth","mimic3","azure","11labs","gcp","openai","convai"],"description":"Text-to-Speech service options. Used to generate your voice.","_title":"Player TTS"},
  "TTSFUNCTION_PLAYER_VOICE": {"type":"string","userlvl":"basic","scope":"global","description":"VoiceID to use for the player character."},
  "STTFUNCTION": {
    "type":"select","values":["whisper","localwhisper","azure","deepgram"],"description":"Speech-to-Text service options. Translates your voice to text.", 
    "_title":"Speech-to-Text Service","scope":"global"
    },
  "STT": {
  "_title":"Speech-to-Text Service",
    "WHISPER": {
      "_title":"OpenAI's Whisper",
      "LANG": {"type":"string","description":"Language to detect for STT."},
      "TRANSLATE": {"type":"boolean","description":"Will try to translate to english."},
      "API_KEY": {"type":"apikey","description":"OpenAI API key. Same used for OpenAI/ChatGPT AI service.","code":"OPENAI_API_KEY"}
    },
    "AZURE": {
      "_title":"Azure Speech-to-Text",
      "LANG": {"type":"string","description":"Language to detect for STT."},
      "profanity": {"type":"select","values":["masked","removed","raw"],"description":"Specifies how to handle profanity in recognition results. Accepted values are:<br>MASKED, which replaces profanity with asterisks.<br>REMOVED, which removes all profanity from the result.<br>RAW, which includes profanity in the result.","helpurl":"https://learn.microsoft.com/en-us/azure/ai-services/speech-service/rest-speech-to-text-short"},
      "API_KEY": {"type":"apikey","description":"Azure API key. Same used for Azure TTS Service.","code":"AZURE_API_KEY"}
    },
    "LOCALWHISPER": {
      "_title":"Local Whisper (Installed in DwemerDistro)",
      "URL": {"type":"url","description":"Local whisper endpoint. Leave as Default if you installed whisper through the Distro.","helpurl":"https://www.nexusmods.com/skyrimspecialedition/mods/89931?tab=files"},
      "FORMFIELD": {"type":"select","values":["audio_file","file"],"description":"Form field name for audio file. Sometimes needed to change to file to use another shiper implementations"}
    },"DEEPGRAM": {
      "_title":"Deepgram's Whisper Speech-to-Text",
      "API_KEY": {"type":"apikey","description":"Deepgram API key.","code":"DEEPGRAM_API_KEY"},
      "LANG":{"type":"string","description":"Language"},
      "MODEL":{"type":"select","values":["nova-2","whisper-medium","enhanced","nova","base"],"description":"Model to use"}
    }
  },
  "ITTFUNCTION": {
    "type":"select","values":["openai","llamacpp"],"description":"Image recognition aka Soulgaze spell. OpenAI also works as a connector to OpenRouter!<br><br><strong>Must be configured in default profile!</strong>", 
    "_title":"Soulgaze (ITT)","scope":"global",
    "quality": {"type":"int","description":"Only when using Soulgaze HD. Compression quality from 0 (lower and unusable) to 100 (near no compression). More quality means higher file size, ergo more tokens.","scope":"global"}
  },
  "ITT": {
    "openai": {
      "_title":"OpenAI/OpenRouter",
      "url": {"type":"url","description":"OpenAI API or OpenRouter endpoint. Use this for OpenRouter (https://openrouter.ai/api/v1/chat/completions)","scope":"global"},
      "model": {"type":"string","description":"Model to use","helpurl":"https://platform.openai.com/docs/models/","scope":"global"},
      "max_tokens": {"type":"integer","description":"Maximum tokens to generate","scope":"global"},
      "detail": {"type":"select","values":["low","high"],"description":"Low or high fidelity image understanding","helpurl":"https://platform.openai.com/docs/guides/vision?lang=curl","scope":"global"},
      "API_KEY":  {"type":"apikey","description":"OpenAI API key","code":"OPENAI_API_KEY","helpurl":"https://platform.openai.com/account/api-keys","scope":"global"},
      "AI_VISION_PROMPT": {"type":"longstring","description":"Prompt to send to the OpenAI vision model.","scope":"global"},
      "AI_PROMPT": {"type":"longstring","description":"Prompt for the AI NPC to follow when describing the scene."}
    },
    "LLAMACPP": {
      "_title":"LLama Server (Installed in DwemerDistro)",
      "URL": {"type":"url","description":"URL of the llama.cpp server","helpurl":"https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md","scope":"global"},
      "AI_VISION_PROMPT": {"type":"longstring","description":"Prompt to send to the llama vision model.","scope":"global"},
      "AI_PROMPT": {"type":"longstring","description":"Prompt for the AI NPC to follow when describing the scene."}
    }
  },
  "FEATURES": {
    "_title":"Memory Configuration",
    "MEMORY_EMBEDDING": {
      "_title":"Memory Settings",
      "ENABLED": {"type":"boolean","description":"<Strong>Make sure CONNECTORS_DIARY is setup!</strong> Enable long term memory. It will provide the most relevant memory with every AI response to be used as context."},
      "TXTAI_URL": {"type":"url","description":"NOT FUNCTIONAL CURRENTLY. JUST LEAVE AS IS!"},
      "MEMORY_TIME_DELAY": {"type":"integer","description":"Time in minutes to delay before using a memory in a prompt. Used to avoid pushing recent dialogues as memories."},
      "MEMORY_CONTEXT_SIZE": {"type":"integer","description":"The amount of the most relevant memory records that will be injected into the prompt."},
      "AUTO_CREATE_SUMMARYS": {"type":"boolean","description":"Will combine individual memory logs into larger ones. Is more accurate for memory recollection but will use up more tokens. If using koboldcpp, use the multiuser mode to avoid locking."},
      "AUTO_CREATE_SUMMARY_INTERVAL": {"type":"integer","description":"Time frame used to pack summary data. 10 = 13 in-game hours | 5 = 7.5 in-game hours etc"},
      "MEMORY_BIAS_A": {"type":"number","description":"From 0 (never) to 100 (always). Minimal distance to offer memory."},
      "MEMORY_BIAS_B": {"type":"number","description":"From 0 (never) to 100 (always). Minimal distance to offer and endorse memory."}
      
    },
  "MISC": {
    "_title":"Other Options",
    "ADD_TIME_MARKS":{"type":"boolean","description":"Add timestamps to the context logs. Helps with memory recollection."},
    "QUEST_COMMENT":{"type":"boolean","description":"Will trigger AI to talk about new objectives in your current quest. Will trigger a lot of events on new game, so shoudl activated on loaded games"},
    "ITT_QUALITY": {"type":"integer","description":"Only for Soulgaze HD. Compression quality can be set from 0 (lower and unusable) to 100 (near no compression). More quality means higher file size, ergo more tokens.","scope":"global"},
    "TTS_RANDOM_PITCH": {"type":"boolean","userlvl":"pro","description":"WIP DO NOT USE! Adjusting the pitch when generating the voice for this actor will add variation, so actors using the same voice sound slightly distinct."},
    "OGHMA_INFINITUM": {"type":"boolean","userlvl":"pro","description":"WIP DO NOT USE! Needs minime enabled. Skyrim context information will be added to the prompt, enhancing the understanding of LLMs that lack specific knowledge about Skyrim."},
    "JSON_DIALOGUE_FORMAT_REORDER": {"type":"boolean","userlvl":"pro","description":"Reorders properties in the offered JSON schema. Some users report better action trigering using this"}

   }
  }
  
}
